{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhammf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\muhammf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.9414414414414415 0.825 1.0 0.9041095890410958\n",
      "1\n",
      "0.9316888045540797 0.9809264305177112 0.7809110629067245 0.8695652173913043\n",
      "2\n",
      "0.9660163624921334 0.891566265060241 1.0 0.9426751592356688\n",
      "3\n",
      "0.9570815450643777 0.8715596330275229 1.0 0.9313725490196079\n",
      "4\n",
      "0.8832612723903644 0.9657794676806084 0.5852534562211982 0.7288378766140603\n",
      "5\n",
      "0.9510835913312693 0.8725868725868726 0.9720430107526882 0.9196337741607324\n",
      "6\n",
      "0.9772167487684729 0.9827213822894169 0.9400826446280992 0.9609292502639917\n",
      "7\n",
      "0.8544891640866873 0.9674418604651163 0.47706422018348627 0.6390168970814132\n",
      "8\n",
      "0.9243597379392495 1.0 0.7495069033530573 0.8568207440811725\n",
      "9\n",
      "0.9957291031116534 0.9879759519038076 0.9979757085020243 0.9929506545820747\n",
      "10\n",
      "0.9474969474969475 0.8539741219963032 0.9850746268656716 0.9148514851485149\n",
      "11\n",
      "0.9353264185478951 0.8812260536398467 0.9126984126984127 0.8966861598440545\n",
      "12\n",
      "0.8837492391965917 0.8574660633484162 0.747534516765286 0.7987355110642781\n",
      "13\n",
      "0.9436964504283966 0.84 1.0 0.9130434782608696\n",
      "14\n",
      "0.9404052443384983 0.9097888675623801 0.8994307400379506 0.9045801526717557\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "all_trained_models = []\n",
    "\n",
    "all_score = []\n",
    "\n",
    "all_training_index = []\n",
    "all_testing_index = []\n",
    "\n",
    "file_to_read = open(\"features/all_training_features.pickle\", \"rb\")\n",
    "X_train = pickle.load(file_to_read)\n",
    "file_to_read.close()\n",
    "\n",
    "file_to_read = open(\"features/all_training_labels.pickle\", \"rb\")\n",
    "y_train = pickle.load(file_to_read)\n",
    "file_to_read.close()\n",
    "\n",
    "X_train_df = pd.concat(X_train)\n",
    "y_train_df = pd.concat(y_train)\n",
    "\n",
    "\n",
    "model.fit(X_train_df, y_train_df)\n",
    "\n",
    "output_name = 'result_centralized.csv' \n",
    "\n",
    "with open(output_name, 'a',newline='', encoding='utf-8') as csvFile:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(csvFile)\n",
    "    # append a row to the csv file\n",
    "    writer.writerow(['subject_number', 'acc', 'prec', 'rec', 'f1'])\n",
    "\n",
    "for idx in range(15):\n",
    "    file_to_read = open(\"features/testing_features\"+str(idx)+\".pickle\", \"rb\")\n",
    "    X_test = pickle.load(file_to_read)\n",
    "    file_to_read.close()\n",
    "\n",
    "    file_to_read = open(\"features/testing_labels\"+str(idx)+\".pickle\", \"rb\")\n",
    "    y_test = pickle.load(file_to_read)\n",
    "    file_to_read.close()\n",
    "\n",
    "    print(idx)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc=accuracy_score(y_test, y_pred)\n",
    "    prec=precision_score(y_test, y_pred, pos_label=2)\n",
    "    rec=recall_score(y_test, y_pred, pos_label=2)\n",
    "    f1=f1_score(y_test, y_pred, pos_label=2)\n",
    "    print(acc, prec, rec, f1)\n",
    "\n",
    "    # open the file in the append mode\n",
    "    with open(output_name, 'a',newline='', encoding='utf-8') as csvFile:\n",
    "        # create the csv writer\n",
    "        writer = csv.writer(csvFile)\n",
    "        # append a row to the csv file\n",
    "        writer.writerow([idx, acc, prec, rec, f1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
